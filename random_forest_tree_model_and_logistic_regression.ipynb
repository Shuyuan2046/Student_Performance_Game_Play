{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-04-24T01:40:23.335823Z",
     "iopub.status.busy": "2023-04-24T01:40:23.334536Z",
     "iopub.status.idle": "2023-04-24T01:40:23.348927Z",
     "shell.execute_reply": "2023-04-24T01:40:23.347836Z",
     "shell.execute_reply.started": "2023-04-24T01:40:23.335770Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-24T01:37:24.974365Z",
     "iopub.status.busy": "2023-04-24T01:37:24.973986Z",
     "iopub.status.idle": "2023-04-24T01:37:26.524742Z",
     "shell.execute_reply": "2023-04-24T01:37:26.523697Z",
     "shell.execute_reply.started": "2023-04-24T01:37:24.974331Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "dtypes = {\n",
    "    'elapsed_time': int,\n",
    "    'event_name': 'category',\n",
    "    'name': 'category',\n",
    "    'level': int,\n",
    "    'room_coor_x': float,\n",
    "    'room_coor_y': float,\n",
    "    'screen_coor_x': float,\n",
    "    'screen_coor_y': float,\n",
    "    'hover_duration': float,\n",
    "    'text': 'category',\n",
    "    'fqid': 'category',\n",
    "    'room_fqid': 'category',\n",
    "    'text_fqid': 'category',\n",
    "    'fullscreen': 'category',\n",
    "    'hq': 'category',\n",
    "    'music': 'category',\n",
    "    'level_group': 'category'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-24T01:40:27.195073Z",
     "iopub.status.busy": "2023-04-24T01:40:27.194649Z",
     "iopub.status.idle": "2023-04-24T01:42:37.511625Z",
     "shell.execute_reply": "2023-04-24T01:42:37.510570Z",
     "shell.execute_reply.started": "2023-04-24T01:40:27.195033Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_df = pd.read_csv('/kaggle/input/predict-student-performance-from-game-play/train.csv', dtype=dtypes)\n",
    "\n",
    "CATEGORICAL = ['event_name', 'name', 'fqid', 'room_fqid', 'text_fqid']\n",
    "NUMERICAL = ['elapsed_time', 'level', 'page', 'room_coor_x', 'room_coor_y','screen_coor_x', 'screen_coor_y', 'hover_duration']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-24T01:43:10.787552Z",
     "iopub.status.busy": "2023-04-24T01:43:10.787120Z",
     "iopub.status.idle": "2023-04-24T01:43:10.796638Z",
     "shell.execute_reply": "2023-04-24T01:43:10.795310Z",
     "shell.execute_reply.started": "2023-04-24T01:43:10.787513Z"
    }
   },
   "outputs": [],
   "source": [
    "def feature_engineer(dataset_df):\n",
    "\n",
    "    # Initialize an empty dictionary to store aggregation functions for each feature.\n",
    "    agg_dict = {}\n",
    "\n",
    "    # Loop through categorical features and add 'nunique' to aggregation dictionary.\n",
    "    for c in CATEGORICAL:\n",
    "        agg_dict[c] = ['nunique']\n",
    "\n",
    "    # Loop through numerical features and add 'mean' and 'std' to aggregation dictionary.\n",
    "    for c in NUMERICAL:\n",
    "        agg_dict[c] = ['mean', 'std']\n",
    "\n",
    "    # Initialize an empty list to store aggregated dataframes.\n",
    "    dfs = []\n",
    "\n",
    "    # Loop through unique values of the 'level_group' column.\n",
    "    for group in dataset_df['level_group'].unique():\n",
    "\n",
    "        # Select a subset of the input dataset that corresponds to the current group.\n",
    "        group_df = dataset_df[dataset_df['level_group'] == group]\n",
    "\n",
    "        # Group the data by session_id and calculate the aggregates specified in agg_dict.\n",
    "        agg_df = group_df.groupby(['session_id'])[NUMERICAL+CATEGORICAL].agg(agg_dict)\n",
    "\n",
    "        # Rename columns to combine original column names and aggregation function names.\n",
    "        agg_df.columns = ['_'.join(col).strip() for col in agg_df.columns.values]\n",
    "\n",
    "        # Fill any missing values with -1 and add a new 'level_group' column.\n",
    "        agg_df = agg_df.fillna(-1)\n",
    "        agg_df['level_group'] = group\n",
    "\n",
    "        # Append the aggregated dataframe to the list.\n",
    "        dfs.append(agg_df)\n",
    "\n",
    "    # Concatenate all the aggregated dataframes and reset the index to session_id.\n",
    "    dataset_df = pd.concat(dfs).reset_index()\n",
    "    dataset_df = dataset_df.set_index('session_id')\n",
    "\n",
    "    return dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-24T01:43:17.222010Z",
     "iopub.status.busy": "2023-04-24T01:43:17.221591Z",
     "iopub.status.idle": "2023-04-24T01:43:37.822118Z",
     "shell.execute_reply": "2023-04-24T01:43:37.820774Z",
     "shell.execute_reply.started": "2023-04-24T01:43:17.221975Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_df = feature_engineer(dataset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-24T01:43:44.423463Z",
     "iopub.status.busy": "2023-04-24T01:43:44.423040Z",
     "iopub.status.idle": "2023-04-24T01:43:45.552541Z",
     "shell.execute_reply": "2023-04-24T01:43:45.551437Z",
     "shell.execute_reply.started": "2023-04-24T01:43:44.423418Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract all unique users from the input dataset.\n",
    "ALL_USERS = dataset_df.index.unique()\n",
    "\n",
    "# Extract all features except 'level_group' from the input dataset.\n",
    "FEATURES = [c for c in dataset_df.columns if c != 'level_group']\n",
    "\n",
    "# Load target labels from a CSV file.\n",
    "targets = pd.read_csv('/kaggle/input/predict-student-performance-from-game-play/train_labels.csv')\n",
    "\n",
    "# Extract the session ID from each target label and convert it to an integer.\n",
    "targets['session'] = targets.session_id.apply(lambda x: int(x.split('_')[0]))\n",
    "\n",
    "# Extract the question number from each target label and convert it to an integer.\n",
    "targets['q'] = targets.session_id.apply(lambda x: int(x.split('_')[-1][1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to determine the level group based on the value of t\n",
    "def get_level_group(t):\n",
    "    if t <= 3:\n",
    "        return '0-4'\n",
    "    elif t <= 13:\n",
    "        return '5-12'\n",
    "    else:\n",
    "        return '13-22'\n",
    "\n",
    "# Function to prepare data by filtering rows based on level group and question number (q)\n",
    "def prepare_data(df, targets, level_group, q):\n",
    "    df_filtered = df.loc[df.level_group == level_group]\n",
    "    users = df_filtered.index.values\n",
    "    y = targets.loc[targets.q == q].set_index('session').loc[users]\n",
    "    return df_filtered[FEATURES], y['correct']\n",
    "\n",
    "# Function to train a classifier and make predictions\n",
    "def train_and_predict(clf, train_x, train_y, valid_x):\n",
    "    clf.fit(train_x, train_y)\n",
    "    return clf.predict(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a KFold object with 5 splits, shuffling the data and setting a random seed of 42\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize DataFrames for out-of-fold predictions\n",
    "oof_rfc = pd.DataFrame(data=np.zeros((len(ALL_USERS), 18)), index=ALL_USERS)\n",
    "oof_lr = oof_rfc.copy()\n",
    "\n",
    "# Iterate over each fold\n",
    "for train_index, test_index in kf.split(X=dataset_df):\n",
    "    # Iterate over each question (t)\n",
    "    for t in range(1, 19):\n",
    "        # Determine the level group for the current question\n",
    "        level_group = get_level_group(t)\n",
    "        \n",
    "        # Prepare the training and validation datasets\n",
    "        train_x, train_y = prepare_data(dataset_df.iloc[train_index], targets, level_group, t)\n",
    "        valid_x, valid_y = prepare_data(dataset_df.iloc[test_index], targets, level_group, t)\n",
    "        valid_users = valid_x.index.values\n",
    "        \n",
    "        # Train RandomForestClassifier and make predictions\n",
    "        clf_rfc = RandomForestClassifier(n_estimators=100)\n",
    "        preds_rfc = train_and_predict(clf_rfc, train_x, train_y, valid_x)\n",
    "        oof_rfc.loc[valid_users, t-1] = preds_rfc\n",
    "        \n",
    "        # Train LogisticRegression and make predictions\n",
    "        clf_lr = LogisticRegression(C=1, max_iter=1000, penalty='l2')\n",
    "        preds_lr = train_and_predict(clf_lr, train_x, train_y, valid_x)\n",
    "        oof_lr.loc[valid_users, t-1] = preds_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_values(true, targets):\n",
    "    for k in range(18):\n",
    "        tmp = targets.loc[targets.q == k+1].set_index('session').loc[ALL_USERS]\n",
    "        true[k] = tmp.correct.values\n",
    "    return true\n",
    "\n",
    "def get_best_threshold_and_f1_score(true, oof):\n",
    "    thresholds = np.arange(0.2, 0.8, 0.01)\n",
    "    f1_scores = []\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        preds = (oof.values.reshape(-1) > threshold).astype(int)\n",
    "        f1_score = precision_recall_fscore_support(true.values.reshape(-1), preds, average='macro')[2]\n",
    "        f1_scores.append(f1_score)\n",
    "\n",
    "    best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "    best_f1_score = np.max(f1_scores)\n",
    "\n",
    "    return best_threshold, best_f1_score\n",
    "\n",
    "def print_f1_scores_per_question(true, oof, best_threshold):\n",
    "    for k in range(18):\n",
    "        f1_score = precision_recall_fscore_support(true[k], (oof[k] > best_threshold).astype(int), average='macro')[2]\n",
    "        print(f'Question {k+1} macro F1 score: {f1_score}')\n",
    "\n",
    "def evaluate_model(oof, targets):\n",
    "    true = oof.copy()\n",
    "    true = get_true_values(true, targets)\n",
    "    best_threshold, best_f1_score = get_best_threshold_and_f1_score(true, oof)\n",
    "\n",
    "    print('Best threshold:', best_threshold)\n",
    "    print('Best macro F1 score:', best_f1_score)\n",
    "\n",
    "    print_f1_scores_per_question(true, oof, best_threshold)\n",
    "\n",
    "    macro_f1_score = precision_recall_fscore_support(true.values.reshape(-1), (oof.values.reshape(-1) > best_threshold).astype(int), average='macro')[2]\n",
    "    print('Overall macro F1 score:', macro_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate RandomForest\n",
    "evaluate_model(oof_rfc, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Logistic regression \n",
    "\n",
    "evaluate_model(oof_lr, targets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
